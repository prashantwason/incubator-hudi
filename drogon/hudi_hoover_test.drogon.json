{
  "project_name": "hudi_hoover_test_suite",
  "project_hdfs_dir": "/user/${UBER_LDAP_UID}/hudi_test_suite/",

  "deployment": {
    "artifacts": {
      "file": "packaging/hudi-integ-test-bundle/target/hudi-integ-test-bundle-${HUDI_VERSION}.jar",
      "files": [
        "${DAG_FILEPATH}",
        "${PROPERTIES_FILEPATH}",
        "${SCHEMA_FILEPATH}"
      ]
    },
    "flatten_directories": true
  },

  "launch": {
    "className": "org.apache.hudi.integ.testsuite.HoodieTestSuiteJob",
    "jars": [
      "https://repo1.maven.org/maven2/org/apache/spark/spark-avro_2.11/2.4.4/spark-avro_2.11-2.4.4.jar",
      "https://repo1.maven.org/maven2/com/databricks/spark-avro_2.11/4.0.0/spark-avro_2.11-4.0.0.jar",
      "https://repo1.maven.org/maven2/org/apache/spark/spark-hive-thriftserver_2.12/3.0.0-preview2/spark-hive-thriftserver_2.12-3.0.0-preview2.jar",
      "https://repo1.maven.org/maven2/org/apache/hive/hive-common/${HIVE_VERSION}/hive-common-${HIVE_VERSION}.jar",
      "https://repo1.maven.org/maven2/org/apache/hive/hive-exec/${HIVE_VERSION}/hive-exec-${HIVE_VERSION}-core.jar",
      "https://repo1.maven.org/maven2/org/apache/hive/hive-jdbc/${HIVE_VERSION}/hive-jdbc-${HIVE_VERSION}.jar",
      "https://repo1.maven.org/maven2/org/apache/hive/hive-llap-common/${HIVE_VERSION}/hive-llap-common-${HIVE_VERSION}.jar",
      "https://repo1.maven.org/maven2/org/apache/hive/hive-metastore/${HIVE_VERSION}/hive-metastore-${HIVE_VERSION}.jar",
      "https://repo1.maven.org/maven2/org/apache/hive/hive-serde/${HIVE_VERSION}/hive-serde-${HIVE_VERSION}.jar",
      "https://repo1.maven.org/maven2/org/apache/hive/hive-service/${HIVE_VERSION}/hive-service-${HIVE_VERSION}.jar",
      "https://repo1.maven.org/maven2/org/apache/hive/hive-service-rpc/${HIVE_VERSION}/hive-service-rpc-${HIVE_VERSION}.jar",
      "https://repo1.maven.org/maven2/org/apache/hive/shims/hive-shims-0.23/${HIVE_VERSION}/hive-shims-0.23-${HIVE_VERSION}.jar",
      "https://repo1.maven.org/maven2/org/apache/hive/shims/hive-shims-common/${HIVE_VERSION}/hive-shims-common-${HIVE_VERSION}.jar",
      "https://repo1.maven.org/maven2/org/apache/hive/hive-storage-api/${HIVE_VERSION}/hive-storage-api-${HIVE_VERSION}.jar",
      "https://repo1.maven.org/maven2/org/apache/hive/hive-shims/${HIVE_VERSION}/hive-shims-${HIVE_VERSION}.jar",
      "viewfs://ns-default/user/hoover/jvm_profiler/uber-java-agent-1.2.0-jar-with-dependencies.jar"
    ],
    "args": [
      "--source-ordering-field", "_row_key",
      "--target-base-path", "${BASE_PATH}",
      "--input-base-path", "/user/${UBER_LDAP_UID}/hudi_test_suite/${TABLE_NAME}/input",
      "--target-table", "${TABLE_NAME}",
      "--props", "/user/${UBER_LDAP_UID}/hudi_test_suite/dev_${UBER_LDAP_UID}/${PROPERTIES_FILENAME}",
      "--schemaprovider-class", "org.apache.hudi.utilities.schema.HudiDatasetSchemaProvider",
      "--source-class", "org.apache.hudi.utilities.sources.HoodieIncrSource",
      "--input-file-size", "1073741824",
      "--workload-yaml-path", "/user/${UBER_LDAP_UID}/hudi_test_suite/dev_${UBER_LDAP_UID}/${DAG_FILENAME}",
      "--table-type", "${TABLE_TYPE}",
      "--workload-generator-classname", "yaml",
      "--input-parallelism", "${INPUT_PARALLELISM}",
      "--delete-old-input",
      "--clean-input",
      "--filesystem-class", "org.apache.hudi.integ.testsuite.fs.HoodieUnionFileSystem"
    ],
    "conf": {
      "spark.yarn.jars.exclusionRegex": "(hive.*)|(spark-hive-thriftserver.*)|(.*hudi.*)",
      "spark.driver.extraClassPath": "hive-common-${HIVE_VERSION}.jar:hive-exec-${HIVE_VERSION}-core.jar:hive-jdbc-${HIVE_VERSION}.jar:hive-llap-common-${HIVE_VERSION}.jar:hive-metastore-${HIVE_VERSION}.jar:hive-serde-${HIVE_VERSION}.jar:hive-service-${HIVE_VERSION}.jar:hive-service-rpc-${HIVE_VERSION}.jar:hive-shims-0.23-${HIVE_VERSION}.jar:hive-shims-common-${HIVE_VERSION}.jar:hive-storage-api-${HIVE_VERSION}.jar:hive-shims-${HIVE_VERSION}.jar:spark-hive-thriftserver_2.12-3.0.0-preview2.jar:log4j-core-2.6.2.jar:log4j-api-2.6.2.jar",
      "spark.executor.extraClassPath": "hive-common-${HIVE_VERSION}.jar:hive-exec-${HIVE_VERSION}-core.jar:hive-jdbc-${HIVE_VERSION}.jar:hive-llap-common-${HIVE_VERSION}.jar:hive-metastore-${HIVE_VERSION}.jar:hive-serde-${HIVE_VERSION}.jar:hive-service-${HIVE_VERSION}.jar:hive-service-rpc-${HIVE_VERSION}.jar:hive-shims-0.23-${HIVE_VERSION}.jar:hive-shims-common-${HIVE_VERSION}.jar:hive-storage-api-${HIVE_VERSION}.jar:hive-shims-${HIVE_VERSION}.jar:spark-hive-thriftserver_2.12-3.0.0-preview2.jar:log4j-core-2.6.2.jar:log4j-api-2.6.2.jar",
      
      "spark.shuffle.file.buffer": "2m",
      "spark.driver.cores": "4",
      "spark.executor.cores": "2",
      "spark.eventLog.compress": "false",
      "spark.yarn.maxAppAttempts": "1",
      "spark.blacklist.enabled": "true",
      "spark.task.maxFailures": "5",
      "spark.broadcast.compress": "false",
      "spark.files.fetchTimeout": "90s",
      "spark.scheduler.maxRegisteredResourcesWaitingTime": "600s",
      "spark.driver.extraJavaOptions": "-XX:+OptimizeStringConcat -XX:+PrintFlagsFinal -XX:+PrintReferenceGC -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintAdaptiveSizePolicy -XX:+UnlockDiagnosticVMOptions -XX:+HeapDumpOnOutOfMemoryError -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+ScavengeBeforeFullGC -XX:+CMSScavengeBeforeRemark -XX:+UseCMSInitiatingOccupancyOnly -XX:CompressedClassSpaceSize=256m -javaagent:uber-java-agent-1.2.0-jar-with-dependencies.jar=tag=hudi-test-suite_driver,metricInterval=10000,durationProfiling=org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.*",
      "spark.executor.extraJavaOptions": "-XX:+OptimizeStringConcat -XX:+PrintFlagsFinal -XX:+PrintReferenceGC -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintAdaptiveSizePolicy -XX:+UnlockDiagnosticVMOptions -XX:+HeapDumpOnOutOfMemoryError -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+ScavengeBeforeFullGC -XX:+CMSScavengeBeforeRemark -XX:+UseCMSInitiatingOccupancyOnly -XX:CompressedClassSpaceSize=256m ",
      "spark.scheduler.minRegisteredResourcesRatio": "0.9",
      "spark.eventLog.buffer.kb": "20480",
      "spark.scheduler.listenerbus.eventqueue.size": "200000",
      "spark.shuffle.compress": "true",
      "spark.executor.logs.rolling.maxRetainedFiles": "3",
      "spark.shuffle.io.preferDirectBufs": "true",
      "spark.rdd.compress": "true",
      "spark.ui.port": "25432",
      "spark.locality.wait.process": "3s",
      "spark.eventLog.enabled": "true",
      "spark.io.compression.lz4.blockSize": "128k",
      "spark.memory.offHeap.enabled": "false",
      "spark.executor.logs.rolling.maxSize": "104857600",
      "spark.locality.wait.rack": "0s",
      "spark.shuffle.io.serverThreads": "1",
      "spark.shuffle.service.enabled": "true",
      "spark.network.timeout": "600s",
      "spark.shuffle.io.backLog": "2",
      "spark.executor.heartbeatInterval": "120s",
      "spark.default.parallelism": "1024",
      "spark.eventLog.flush": "false",
      "spark.memory.fraction": "0.6",
      "spark.driver.memory": "8g",
      "spark.executor.memory": "8g",
      "spark.shuffle.io.numConnectionsPerPeer": "1",
      "spark.shuffle.spill.initialMemoryThreshold": "209715200",
      "spark.kryoserializer.buffer": "2m",
      "spark.blacklist.task.maxTaskAttemptsPerExecutor": "2",
      "spark.shuffle.sort.initialBufferSize": "4194304",
      "spark.locality.wait.node": "0s",
      "spark.shuffle.spill.compress": "true",
      "spark.memory.storageFraction": "0.2",
      "spark.unsafe.sorter.spill.reader.buffer.size": "2m",
      "spark.storage.uber.memoryMapLimit": "6g",
      "spark.shuffle.service.index.cache.entries": "2048",
      "spark.reducer.maxReqsInFlight": "320",
      "spark.shuffle.io.retryWait": "10s",
      "spark.shuffle.service.port": "7337",
      "spark.serializer": "org.apache.spark.serializer.KryoSerializer",
      "spark.reducer.maxSizeInFlight": "6m",
      "spark.authenticate": "false",
      "spark.shuffle.consolidateFiles": "true",
      "spark.yarn.am.waitTime": "100s",
      "spark.driver.maxResultSize": "6g",
      "spark.kryo.classesToRegister": "java.util.ArrayList,org.apache.hudi.common.model.HoodieRecord,org.apache.hudi.common.model.HoodieKey,java.util.Optional,com.google.common.base.Optional,java.util.HashMap,com.google.common.base.Absent,org.apache.avro.util.Utf8,java.lang.Class,com.google.common.base.Present,scala.reflect.ClassTag$$anon$1,org.apache.spark.util.AccumulatorMetadata,java.util.concurrent.TimeUnit,org.apache.hudi.common.HoodieRollbackStat,org.apache.hadoop.fs.FileStatus,org.apache.hadoop.fs.Path,org.apache.hadoop.hdfs.protocol.FsPermissionExtension,org.apache.hadoop.fs.permission.FsAction,org.apache.hudi.common.model.HoodieWriteStat,java.util.concurrent.atomic.AtomicLong,java.util.HashSet,java.util.concurrent.ConcurrentHashMap,org.apache.hudi.client.WriteStatus,org.apache.hudi.common.model.HoodieRecordLocation,org.apache.hudi.common.model.HoodieBaseFile,org.apache.hudi.index.bloom.BloomIndexFileInfo,org.apache.hudi.common.model.OverwriteWithLatestAvroPayload",
      "spark.dynamicAllocation.enabled": false,
      "spark.shuffle.service.enabled": true,
      "spark.serializer": "org.apache.spark.serializer.KryoSerializer"
    },
    "numExecutors": 512,
    "queue": "hadoop-platform-adhoc",
    "sparkEnv": "SPARK_24"
  },

  "build": {
    "shell_command": "mvn package -DskipTests -Dcheckstyle.skip",
    "cd_enabled": false
  },

  "variables": {
    "HIVE_VERSION": "2.3.1",
    "BASE_PATH": "",
    "UBER_LDAP_UID": "hudi",
    "TABLE_NAME": "",
    "DAG_FILEPATH": "",
    "PROPERTIES_FILEPATH": "",
    "SCHEMA_FILEPATH": "",
    "DAG_FILENAME": "",
    "PROPERTIES_FILENAME": "",
    "SCHEMA_FILENAME": "",
    "HUDI_VERSION": "",
    "INPUT_PARALLELISM": "-1",
    "TABLE_TYPE": "COPY_ON_WRITE",
    "NUM_EXECUTORS": 512
  }
}
